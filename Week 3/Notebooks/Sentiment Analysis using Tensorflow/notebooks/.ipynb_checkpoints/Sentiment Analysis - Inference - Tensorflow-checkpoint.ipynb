{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import json\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/justineclemente/programs/anaconda3/envs/python3_tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "w2i_file = \"../models/word2index.json\"\n",
    "lstm_file = \"../models/best_model_lstm_train.hdf5\"\n",
    "fname = '../datasets/stopwords.txt'\n",
    "\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip() for x in content]\n",
    "\n",
    "word2index=dict()\n",
    "with open(w2i_file) as json_file:\n",
    "    word2index=json.load(json_file)\n",
    "    \n",
    "    \n",
    "dependencies = {\n",
    "    'precision_m': precision_m,\n",
    "    'recall_m': recall_m,\n",
    "    'f1_m': f1_m\n",
    "}\n",
    "\n",
    "model=tf.keras.models.load_model(lstm_file,custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeURLs(message) :\n",
    "\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', message)\n",
    "\n",
    "    dictOfurls = { i : 5 for i in urls }\n",
    "    dictOfurls = dict(map(lambda x: (x[0],''), dictOfurls.items() ))\n",
    "\n",
    "    for k, v in dictOfurls.items():\n",
    "        message = message.replace(k, v)\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeURLs(message) :\n",
    "\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', message)\n",
    "\n",
    "    dictOfurls = { i : 5 for i in urls }\n",
    "    dictOfurls = dict(map(lambda x: (x[0],''), dictOfurls.items() ))\n",
    "\n",
    "    for k, v in dictOfurls.items():\n",
    "        message = message.replace(k, v)\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeURLs2(message) :\n",
    "\n",
    "    urls = re.findall('www.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', message)\n",
    "\n",
    "    dictOfurls = { i : 5 for i in urls }\n",
    "    dictOfurls = dict(map(lambda x: (x[0],''), dictOfurls.items() ))\n",
    "\n",
    "    for k, v in dictOfurls.items():\n",
    "        message = message.replace(k, v)\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function for removing the stop words\n",
    "def remove_stop_words(s):\n",
    "    s_cleaned=[]\n",
    "    for w in s:\n",
    "        if len(w)>=3 and w.lower() not in set(stopwords.words('english')).union(set(content)):\n",
    "            s_cleaned.append(w.strip())\n",
    "    return s_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    #Remove and convert HTML Tags\n",
    "    html_test = html.unescape(text)\n",
    "    soup = BeautifulSoup(re.sub(r'[\\n\\r]', ' ', html_test))\n",
    "    \n",
    "    t2 = soup.get_text()\n",
    "    \n",
    "    #Removing Twitter handles before removing the URLs\n",
    "    t2 = re.sub(r\"(@\\S+)*\", \"\", t2)\n",
    "\n",
    "    #Remove the URLs\n",
    "    t2 = removeURLs(t2)\n",
    "    t2 = removeURLs2(t2)\n",
    "\n",
    "    #Remove remaining https://\n",
    "    t2 = re.sub(r\"https://\", '', t2)\n",
    "\n",
    "    #Remove 't\n",
    "    t2 = re.sub(r\"'nt\", ' not', t2)\n",
    "    t2 = re.sub(r\"'t\", ' not', t2)\n",
    "\n",
    "    #Remove Twitter #s\n",
    "    t2 = re.sub(r\"(#\\S+)*\", \"\", t2)\n",
    "\n",
    "    #Time Cleaning\n",
    "    t2 = re.sub(r'\\d*:\\d+\\s([aApP][mM])', '', t2)\n",
    "    t2 = re.sub(r'\\d*:\\d+([aApP][mM])', '', t2)\n",
    "    t2 = re.sub(r'\\d+\\s?([aApP][mM])', '', t2)\n",
    "    t2 = re.sub(r'\\d+:\\d+', '', t2)\n",
    "\n",
    "    #Special Character Cleaning\n",
    "    t2 = re.sub(r\"( -+ )\", \" \",t2)\n",
    "    t2 = \" \".join([re.sub(r'[^A-Za-zÃ±-]+', ' ', x) for x in t2.split()])\n",
    "    t2 = re.sub(r\"( - )\", \" \", t2)\n",
    "    t2 = re.sub(r\"(\\s-\\w+)\", \" \", t2)\n",
    "    t2 = re.sub(r\"(\\w+-\\s)\", \" \", t2)\n",
    "    t2 = re.sub(r\"( \\w )\", \" \", t2)\n",
    "    #tokenization and removal of stop words\n",
    "    t2 = word_tokenize(t2)\n",
    "    t2_clean = remove_stop_words(t2)\n",
    "    \n",
    "    return t2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(input_text):\n",
    "    input_text_index=[]\n",
    "    for w in input_text:\n",
    "        try:\n",
    "            input_text_index.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            input_text_index.append(word2index['-OOV-'])\n",
    "    return input_text_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(input_text):\n",
    "    MAX_LENGTH=18\n",
    "    print(input_text)\n",
    "    if isinstance(input_text,str):\n",
    "        input_text = preprocessing(input_text)\n",
    "        input_text_index = word_to_index(input_text)\n",
    "        input_text_pad=pad_sequences([input_text_index], maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    else:\n",
    "        #if batch processing\n",
    "        input_text = [preprocessing(text) for text in input_text]\n",
    "        input_text_index = [word_to_index(text) for text in input_text]\n",
    "        input_text_pad=pad_sequences(input_text_index, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    predictions=model.predict(input_text_pad)\n",
    "    predictions_str = predictions.astype(str)\n",
    "    predictions_str[predictions>=0.5] = \"Positive\"\n",
    "    predictions_str[predictions<0.5] = \"Negative\"\n",
    "    return predictions_str.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ang ganda ng produkto\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "sentences = [\"The product is good.\",\"Sira ang produkto.\"]\n",
    "sentence = \"Ang ganda ng produkto\"\n",
    "#classify_sentiment(\"Ang ganda ng produkto.\")\n",
    "sentiments = classify_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF1.14)",
   "language": "python",
   "name": "python3_tf1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
