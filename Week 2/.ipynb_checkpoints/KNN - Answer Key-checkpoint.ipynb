{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Name/Section:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Renz Iver Baliber - G01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbor (kNN) exercise\n",
    "\n",
    "The kNN classifier consists of two stages:\n",
    "\n",
    "- During training, the classifier takes the training data and simply remembers it\n",
    "- During testing, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examples\n",
    "- The value of k is cross-validated\n",
    "\n",
    "In this exercise you will implement these steps and understand the basic classification pipeline, and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with \"A: \" on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how some functions work on the Internet or via the docs. \n",
    "* You may add new cells for \"scrap work\".\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Makes matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is jay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with a small dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small dataset\n",
    "Let's create a simple dataset and see how a kNN classifier will classify it. In this exercise, let's have two class labels 0 and 1, or y = {0,1}\n",
    "\n",
    "Let's first create the X (features) of y=0. We can do this by randomly choosing datapoints with numpy's `np.random.randn function`:\n",
    "```python\n",
    "np.random.randn(rows,cols)*variance + mean\n",
    "```\n",
    "Find out more with `np.random.randn?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 \n",
      "[[5.69301027 1.18659728]\n",
      " [0.46517005 2.11188001]\n",
      " [2.67056632 1.99043603]\n",
      " [1.08634534 5.78925899]\n",
      " [2.63211645 2.87663357]\n",
      " [3.01967559 4.59870402]\n",
      " [1.84410396 2.37146232]\n",
      " [3.13140121 3.8654467 ]\n",
      " [2.12512379 0.8686393 ]\n",
      " [4.71629808 3.10801108]]\n",
      "Class 1 \n",
      "[[-0.96930277 -0.01506919]\n",
      " [ 2.22045653  0.43660156]\n",
      " [ 0.21181919  0.70317449]\n",
      " [ 1.05256668  3.18000238]\n",
      " [ 2.91323113  2.78216208]\n",
      " [ 0.4339702   2.98951093]\n",
      " [ 1.92694898 -0.78984809]\n",
      " [-0.44628122  2.89471021]\n",
      " [ 2.41944142  1.28352816]\n",
      " [-1.04618286  3.11645188]]\n"
     ]
    }
   ],
   "source": [
    "# TODO : Create 10 entries (rows) with 2 features (columns: x and y coordinates) for y=0\n",
    "# Set the mean to 3, and variance to 1.5\n",
    "### START CODE HERE ###\n",
    "X_train_zeros = np.random.randn(10,2)*1.5 + 3\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Create 10 entries (rows) with 2 features (columns) for y=1\n",
    "# Set the mean to 1, and variance to 1.5\n",
    "### START CODE HERE ###\n",
    "X_train_ones = np.random.randn(10,2)*1.5 + 1\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Check the generated numbers\n",
    "print(\"Class 0 \\n\" + str(X_train_zeros))\n",
    "print(\"Class 1 \\n\" + str(X_train_ones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Plot the generated data in a chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e4fcdd0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format: plt.plot(x, y, character/symbol)\n",
    "#plt.plot?\n",
    "\n",
    "# X_train_zeros[:,col] gets all the rows and column col\n",
    "# The 'bo' parameter marks these points as blue circles\n",
    "plt.plot(X_train_zeros[:,0], X_train_zeros[:,1], 'bo')\n",
    "# The 'ro' parameter marks these points as red circles\n",
    "plt.plot(X_train_ones[:,0], X_train_ones[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, our data D has been split to 2 classes. \n",
    "\n",
    "Let's collate them into one X_train, and create y_train for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data set:\n",
      "Features (X) \t\t Label (y)\n",
      "[5.69301027 1.18659728] 0.0\n",
      "[0.46517005 2.11188001] 0.0\n",
      "[2.67056632 1.99043603] 0.0\n",
      "[1.08634534 5.78925899] 0.0\n",
      "[2.63211645 2.87663357] 0.0\n",
      "[3.01967559 4.59870402] 0.0\n",
      "[1.84410396 2.37146232] 0.0\n",
      "[3.13140121 3.8654467 ] 0.0\n",
      "[2.12512379 0.8686393 ] 0.0\n",
      "[4.71629808 3.10801108] 0.0\n",
      "[-0.96930277 -0.01506919] 1.0\n",
      "[2.22045653 0.43660156] 1.0\n",
      "[0.21181919 0.70317449] 1.0\n",
      "[1.05256668 3.18000238] 1.0\n",
      "[2.91323113 2.78216208] 1.0\n",
      "[0.4339702  2.98951093] 1.0\n",
      "[ 1.92694898 -0.78984809] 1.0\n",
      "[-0.44628122  2.89471021] 1.0\n",
      "[2.41944142 1.28352816] 1.0\n",
      "[-1.04618286  3.11645188] 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO : Combine X_train_zeros with X_train_ones to a single matrix\n",
    "# Tip : Use np.concatenate to combine the two matrices\n",
    "### START CODE HERE ###\n",
    "X_train = np.concatenate((X_train_zeros, X_train_ones),0)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Labels\n",
    "# TODO : Create an array of 10 zeros for the first class y=0\n",
    "# Tip : Instead of manually creating an array, use np.zeros\n",
    "### START CODE HERE ###\n",
    "y_train_zeros = np.zeros(10)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Create an array of 10 ones for the first class y=1\n",
    "# Tip : Instead of manually creating an array, use np.ones\n",
    "### START CODE HERE ###\n",
    "y_train_ones = np.ones(10)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Combine y_train_zeros with y_train_ones to a single array\n",
    "# Tip : Use np.concatenate to combine the two arrays\n",
    "### START CODE HERE ###\n",
    "y_train = np.concatenate((y_train_zeros, y_train_ones), axis=0)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"Our data set:\")\n",
    "print(\"Features (X) \\t\\t Label (y)\")\n",
    "for i in range(len(y_train)):\n",
    "    print(str(X_train[i]) + \" \" + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==0.0:\n",
    "        X_train_0.append(X_train[i])\n",
    "X_train_1 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==1.0:\n",
    "        X_train_1.append(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0_ = np.array(X_train_0)\n",
    "X_train_1_ = np.array(X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your output should look like this:__\n",
    "```\n",
    "Our data set:\n",
    "    Features (X) \t\t Label (y)\n",
    "[ 2.10736448  4.38938532] 0.0\n",
    "[ 4.63171067  7.15449636] 0.0\n",
    "[ 2.80923301  2.80047896] 0.0\n",
    "...\n",
    "[ 4.23634568  2.21686253] 1.0\n",
    "[-0.5704331  1.0972354] 1.0\n",
    "[-1.4629462   1.00977947] 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a test case\n",
    "Let's add in a single test case to see how it will be classified by kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ec16e10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New test case, see what will happen when you change this\n",
    "X_test = np.array([[3,3.5]])\n",
    "# There's a reason why this is an array inside an array. Each data \n",
    "# point is represented by an array (currently a array of length 2).\n",
    "# Right now, there is only test data, but soon we many have more than \n",
    "# one.\n",
    "\n",
    "# Plot the original\n",
    "# TODO : plot the data from y=0 with blue circles\n",
    "### START CODE HERE ###\n",
    "plt.plot(X_train_0_[:,0], X_train_0_[:,1], 'bo')\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : plot the data from y=1 with red circles\n",
    "### START CODE HERE ###\n",
    "plt.plot(X_train_1_[:,0], X_train_1_[:,1], 'ro')\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# plot the test case in the figure (it should appear as a black plus sign)\n",
    "# TODO : plot the test data with a black plus\n",
    "### START CODE HERE ###\n",
    "plt.plot(X_test[:,0], X_test[:,1], 'k+')\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN gets the k nearest data points of the test case. Let's envision which nearby data points will be the nearest to our test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Circle at 0x11ecc7f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usual plots\n",
    "# TODO : Plot the y=0 data, y=1 data, and the test data\n",
    "### START CODE HERE ###\n",
    "plt.plot(X_train_0_[:,0], X_train_0_[:,1], 'bo')\n",
    "plt.plot(X_train_1_[:,0], X_train_1_[:,1], 'ro')\n",
    "plt.plot(X_test[:,0], X_test[:,1], 'k+')\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Place in the radius/distance of the circle\n",
    "### START CODE HERE ###\n",
    "radius = 1\n",
    "### END CODE HERE ###\n",
    "\n",
    "circle= plt.Circle((X_test[:,0], X_test[:,1]), radius, color='k', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.axis('equal')\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adjust the radius until it has more than 1 data point. How will you label the new test data?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: On a radius value of 1, the new test data is most likely to be of label \"BLUE\" since the number of label \"Blue\" is more than \"Red\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How will you label it if the circle fits two data points -- one from each class?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: In a case where in the circle fits two data points, and adjusting the circle to have an unequal number of points from each class, choosing the label that seems closer to the point is the label that i will choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit to create a k neighbors classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use scikit learn's KNeighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize our classifier as knn\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be the label of the data point nearest the test data. If the closest data point is blue it should say 0, and 1 if red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Neighbors\n",
    "We could also get the k nearest neighbors (not just the label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model.kneighbors` to get the actual neighbors that are similar to our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 nearest neighbors:\n",
      "1. [3.13140121 3.8654467 ]\t dist: 0.3883523806108853\n",
      "2. [2.91323113 2.78216208]\t dist: 0.7230630132197398\n",
      "3. [2.63211645 2.87663357]\t dist: 0.7238259569477608\n",
      "4. [3.01967559 4.59870402]\t dist: 1.098880182322731\n",
      "5. [2.67056632 1.99043603]\t dist: 1.5450922115870807\n"
     ]
    }
   ],
   "source": [
    "neighbors = 5\n",
    "# TODO : Use kneighbors to get the most similar instances\n",
    "### START CODE HERE ###\n",
    "distances, data_index = model.kneighbors(X_test)\n",
    "### END CODE HERE ###\n",
    "\n",
    "distances = np.squeeze(distances) # just some trivial processing...\n",
    "data_index = np.squeeze(data_index) # just some trivial processing...\n",
    "\n",
    "print(\"The \" + str(neighbors) + \" nearest neighbors:\")\n",
    "for i in range(neighbors):\n",
    "    print(str(i+1) + \". \" + str(X_train[data_index[i]]) + \"\\t dist: \"+ str(distances[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your output should look like this:__\n",
    "```\n",
    "The 5 nearest neighbors:\n",
    "1. [ 3.53308273  3.67087895]\t dist: 0.559800686629\n",
    "2. [ 2.80923301  2.80047896]\t dist: 0.725066710211\n",
    "3. [ 2.25856168  2.97214525]\t dist: 0.910143626575\n",
    "4. [ 3.99191562  2.99839246]\t dist: 1.11153349516\n",
    "5. [ 3.24464637  2.28448593]\t dist: 1.23988963153\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the labels of the k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[data_index]\n",
    "# We can place in an array as the indices to our array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter k\n",
    "\n",
    "By now, you would have noticed that the value of *k* will affect the result the result of the classifier. Choosing a good *k* is important, and we can do sample runs to see which *k* works best for us.\n",
    "\n",
    "*Hyperparameters* like *k* affect how the model learns, and are usually \"set\" before modelling begins. They are different from regular *parameters* in a model. They are normally considered \"higher level\" because they also help estimate model *paramters*. *Parameters* can be estimated by some analytic solution based on the data, while *hyperparameters* can not. Since knn is non-parametric, we haven't encountered any *parameters* yet.\n",
    "\n",
    "In sklearn's KNeighborsClassifier, we can control the value of *k*, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can change the test data to get a more conflicting labels in the neighbors\n",
    "X_test=[[2,2]] \n",
    "# TODO : Add in the parameter for KNeighborsClassifier so that \n",
    "# it will choose 5 neighbors\n",
    "### START CODE HERE ###\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Train the model with the train data\n",
    "### START CODE HERE ###\n",
    "model.fit(X_train, y_train)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Test the model with the test data\n",
    "### START CODE HERE ###\n",
    "model.predict(X_test)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How is the label predicted when k is more 1?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: When k is more than 1, the model, in case of discrete labels, will choose the label that has more instances, while in the case of continous labels, the model will get the mean of the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the effect when you set the neighbors to 1?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The model chooses the label of the instance that is closest to the test data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the effect when you set the neighbors to 20?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A:There is a possibility that the number of instances could lead into a tie, but choosing a high value of K such as 20, would give more options (doesn't necessarily mean that it would be better) for the model to check the data point's neighbors for similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "So far, we only have one test case. But we can test more than one sample data at a time, we just need to populate more samples in our X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change this\n",
    "X_test = [[0,0],[1,1],[2,2],[3,3],[4,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be an array with n elements, where n is the size of X_test. The predictions will come in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, our validation/test data will have proper labels/ground truths to compare our model's predictions with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[0,0],[1,1],[2,2],[3,3],[4,4]]\n",
    "y_test = [    1,    1,    1,    0,   0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the predictions to y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print out the performance metrics given the actual results vs the predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data set\n",
    "We don't need to manually split our training data from test data. Most of the time, manually splitting your data will be a source of partiality because you may un/consciously be choosing \"good\" or \"easy-to-predict\" data for the model to predict.\n",
    "\n",
    "sklearn also has a module that allows us to easily split our data intro training and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Let's first combine X_train and X_test into a single X\n",
    "### START CODE HERE ###\n",
    "X = np.concatenate((X_train, X_test),0)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Let's first combine y_train and y_test into a single y\n",
    "### START CODE HERE ###\n",
    "y = np.concatenate((y_train, y_test),0)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split` to split our train from the test data. Make the test size 33% of the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: \n",
      "[[ 1.92694898 -0.78984809]\n",
      " [ 2.22045653  0.43660156]\n",
      " [ 1.08634534  5.78925899]\n",
      " [ 2.63211645  2.87663357]\n",
      " [ 1.84410396  2.37146232]\n",
      " [ 5.69301027  1.18659728]\n",
      " [ 2.12512379  0.8686393 ]\n",
      " [-1.04618286  3.11645188]\n",
      " [ 3.01967559  4.59870402]\n",
      " [ 2.91323113  2.78216208]\n",
      " [ 4.71629808  3.10801108]\n",
      " [ 0.          0.        ]\n",
      " [ 3.13140121  3.8654467 ]\n",
      " [-0.96930277 -0.01506919]\n",
      " [ 1.05256668  3.18000238]\n",
      " [ 1.          1.        ]]\n",
      "y train: \n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "X test: \n",
      "[[ 4.          4.        ]\n",
      " [ 3.          3.        ]\n",
      " [ 2.          2.        ]\n",
      " [ 2.41944142  1.28352816]\n",
      " [ 0.21181919  0.70317449]\n",
      " [ 2.67056632  1.99043603]\n",
      " [ 0.46517005  2.11188001]\n",
      " [-0.44628122  2.89471021]\n",
      " [ 0.4339702   2.98951093]]\n",
      "y test: \n",
      "[0. 0. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We are going to reuse the variables here...\n",
    "# TODO : Call train_test_split\n",
    "### START CODE HERE ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"X train: \\n\"+ str(X_train))\n",
    "print(\"y train: \\n\"+ str(y_train))\n",
    "print(\"X test: \\n\"+ str(X_test))\n",
    "print(\"y test: \\n\"+ str(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you run the previous cell ang call `train_test_split` again, is it possible to have a different train and test set?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:Yes, the train_test_split module \"shuffles\" or splits the data randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run do modelling like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.75      0.67         4\n",
      "         1.0       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.68      0.68      0.67         9\n",
      "weighted avg       0.68      0.67      0.67         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO : Create a knn classifier with a k of 3\n",
    "### START CODE HERE ###\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think we will come up with a different result if we had a different train and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "Cross validation can be used to decrease the randomness in performance metrics solely because of the test data. \n",
    "\n",
    "__What does cross validation do?__\n",
    "Cross validation is a kind of splitting similar to what we did in the cells before. But it does multiple splits, so cross val will give us *k*   train and test data. It does in such a way that each data point will eventually become a validation data.\n",
    "\n",
    "> The *k* in *k*-fold cross validation is different from *k* nearest neighbors\n",
    "\n",
    "Cross validation is an alternative to split testing where we never shuffle train and test together in further experiments. It is a good option if you have few data points, and you cannot afford to lose any data as test data.\n",
    "\n",
    "__Determining hyperparameters.__ Validation is also a way for us to determine a good value for our *k* in k-nearest neighbors. Instead of blindly choosing our hyperparameter, we will do multiple experiments using cross validation to see which one will give us the best results.\n",
    "\n",
    "> You may have heard of *validation* and *test* data before. For now, we will treat them similarly. But they are two different things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_predict` does the data splitting, training, and cross-validation. Try getting the predictions using a *k* of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75        12\n",
      "         1.0       0.77      0.77      0.77        13\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.76      0.76      0.76        25\n",
      "weighted avg       0.76      0.76      0.76        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "k = 10\n",
    "# TODO : get the predictions using cross_val_predict\n",
    "### START CODE HERE ###\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "predictions = cross_val_predict(model, X, y, cv=3)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : print the classification report\n",
    "### START CODE HERE ###\n",
    "print(classification_report(y, predictions))\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The result should look something like this :__\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.73      0.92      0.81        12\n",
    "        1.0       0.90      0.69      0.78        13\n",
    "\n",
    "avg / total       0.82      0.80      0.80        25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also use `cross_val_score` to get the actual accuracy from each fold in the k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores per fold :\n",
      "[0.66666667 0.75       0.75      ]\n",
      "Average accuracy : 0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# See the scores per fold (experiment)\n",
    "k=3\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "scores = cross_val_score(model, X, y, cv=3)\n",
    "print(\"Scores per fold :\\n\" + str(scores))\n",
    "print(\"Average accuracy : \" + str(np.sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The result should look something like this :__\n",
    "```\n",
    "Scores per fold :\n",
    "[ 1.    0.75  0.    1.    0.5   1.    1.    1.    1.    1.  ]\n",
    "Average accuracy : 0.825\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>fin</center>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
