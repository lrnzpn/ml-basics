{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbor (kNN) exercise\n",
    "\n",
    "The kNN classifier consists of two stages:\n",
    "\n",
    "- During training, the classifier takes the training data and simply remembers it\n",
    "- During testing, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examples\n",
    "- The value of k is cross-validated\n",
    "\n",
    "In this exercise you will implement these steps and understand the basic classification pipeline, and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with \"A: \" on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how some functions work on the Internet or via the docs. \n",
    "* You may add new cells for \"scrap work\".\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Makes matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is jay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with a small dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small dataset\n",
    "Let's create a simple dataset and see how a kNN classifier will classify it. In this exercise, let's have two class labels 0 and 1, or y = {0,1}\n",
    "\n",
    "Let's first create the X (features) of y=0. We can do this by randomly choosing datapoints with numpy's `np.random.randn function`:\n",
    "```python\n",
    "np.random.randn(rows,cols)*variance + mean\n",
    "```\n",
    "Find out more with `np.random.randn?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 \n",
      "[[3.16422732 2.15656922]\n",
      " [3.45334729 2.5996947 ]\n",
      " [2.5211666  3.0916266 ]\n",
      " [1.14581419 4.61391944]\n",
      " [3.3855442  4.09580511]\n",
      " [2.13413999 1.59058297]\n",
      " [3.13309955 3.3110279 ]\n",
      " [2.83166614 4.26439641]\n",
      " [3.79654926 4.54100466]\n",
      " [4.39190021 4.01327191]]\n",
      "Class 1 \n",
      "[[ 1.57102155  1.1552379 ]\n",
      " [ 1.9801191   1.40172117]\n",
      " [-0.79191056  1.08918886]\n",
      " [-1.35304162  0.66777947]\n",
      " [ 0.99356347  0.68182588]\n",
      " [-0.27648426  0.41320186]\n",
      " [ 2.17264155  0.23400838]\n",
      " [ 0.20940424 -0.97223719]\n",
      " [ 1.33512471  1.82438403]\n",
      " [ 2.14877927  0.80819499]]\n"
     ]
    }
   ],
   "source": [
    "# TODO : Create 10 entries (rows) with 2 features (columns: x and y coordinates) for y=0\n",
    "# Set the mean to 3, and variance to 1.5\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Create 10 entries (rows) with 2 features (columns) for y=1\n",
    "# Set the mean to 1, and variance to 1.5\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Check the generated numbers\n",
    "print(\"Class 0 \\n\" + str(X_train_zeros))\n",
    "print(\"Class 1 \\n\" + str(X_train_ones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Plot the generated data in a chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31d012c780>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format: plt.plot(x, y, character/symbol)\n",
    "#plt.plot?\n",
    "\n",
    "# X_train_zeros[:,col] gets all the rows and column col\n",
    "# The 'bo' parameter marks these points as blue circles\n",
    "plt.plot(X_train_zeros[:,0], X_train_zeros[:,1], 'bo')\n",
    "# The 'ro' parameter marks these points as red circles\n",
    "plt.plot(X_train_ones[:,0], X_train_ones[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, our data D has been split to 2 classes. \n",
    "\n",
    "Let's collate them into one X_train, and create y_train for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data set:\n",
      "Features (X) \t\t Label (y)\n",
      "[3.16422732 2.15656922] 0.0\n",
      "[3.45334729 2.5996947 ] 0.0\n",
      "[2.5211666 3.0916266] 0.0\n",
      "[1.14581419 4.61391944] 0.0\n",
      "[3.3855442  4.09580511] 0.0\n",
      "[2.13413999 1.59058297] 0.0\n",
      "[3.13309955 3.3110279 ] 0.0\n",
      "[2.83166614 4.26439641] 0.0\n",
      "[3.79654926 4.54100466] 0.0\n",
      "[4.39190021 4.01327191] 0.0\n",
      "[1.57102155 1.1552379 ] 1.0\n",
      "[1.9801191  1.40172117] 1.0\n",
      "[-0.79191056  1.08918886] 1.0\n",
      "[-1.35304162  0.66777947] 1.0\n",
      "[0.99356347 0.68182588] 1.0\n",
      "[-0.27648426  0.41320186] 1.0\n",
      "[2.17264155 0.23400838] 1.0\n",
      "[ 0.20940424 -0.97223719] 1.0\n",
      "[1.33512471 1.82438403] 1.0\n",
      "[2.14877927 0.80819499] 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO : Combine X_train_zeros with X_train_ones to a single matrix\n",
    "# Tip : Use np.concatenate to combine the two matrices\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Labels\n",
    "# TODO : Create an array of 10 zeros for the first class y=0\n",
    "# Tip : Instead of manually creating an array, use np.zeros\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Create an array of 10 ones for the first class y=1\n",
    "# Tip : Instead of manually creating an array, use np.ones\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Combine y_train_zeros with y_train_ones to a single array\n",
    "# Tip : Use np.concatenate to combine the two arrays\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"Our data set:\")\n",
    "print(\"Features (X) \\t\\t Label (y)\")\n",
    "for i in range(len(y_train)):\n",
    "    print(str(X_train[i]) + \" \" + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==0.0:\n",
    "        X_train_0.append(X_train[i])\n",
    "X_train_1 = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==1.0:\n",
    "        X_train_1.append(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0_ = np.array(X_train_0)\n",
    "X_train_1_ = np.array(X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your output should look like this:__\n",
    "```\n",
    "Our data set:\n",
    "    Features (X) \t\t Label (y)\n",
    "[ 2.10736448  4.38938532] 0.0\n",
    "[ 4.63171067  7.15449636] 0.0\n",
    "[ 2.80923301  2.80047896] 0.0\n",
    "...\n",
    "[ 4.23634568  2.21686253] 1.0\n",
    "[-0.5704331  1.0972354] 1.0\n",
    "[-1.4629462   1.00977947] 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a test case\n",
    "Let's add in a single test case to see how it will be classified by kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f31a504c9b0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New test case, see what will happen when you change this\n",
    "X_test = np.array([[3,3.5]])\n",
    "# There's a reason why this is an array inside an array. Each data \n",
    "# point is represented by an array (currently a array of length 2).\n",
    "# Right now, there is only test data, but soon we many have more than \n",
    "# one.\n",
    "\n",
    "# Plot the original\n",
    "# TODO : plot the data from y=0 with blue circles\n",
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : plot the data from y=1 with red circles\n",
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# plot the test case in the figure (it should appear as a black plus sign)\n",
    "# TODO : plot the test data with a black plus\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN gets the k nearest data points of the test case. Let's envision which nearby data points will be the nearest to our test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Circle at 0x7f31a4fbb390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usual plots\n",
    "# TODO : Plot the y=0 data, y=1 data, and the test data\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Place in the radius/distance of the circle\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "circle= plt.Circle((X_test[:,0], X_test[:,1]), radius, color='k', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.axis('equal')\n",
    "ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adjust the radius until it has more than 1 data point. How will you label the new test data?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How will you label it if the circle fits two data points -- one from each class?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit to create a k neighbors classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use scikit learn's KNeighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize our classifier as knn\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Train the model \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be the label of the data point nearest the test data. If the closest data point is blue it should say 0, and 1 if red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Neighbors\n",
    "We could also get the k nearest neighbors (not just the label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model.kneighbors` to get the actual neighbors that are similar to our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 nearest neighbors:\n",
      "1. [3.13309955 3.3110279 ]\t dist: 0.23114053274676577\n",
      "2. [2.5211666 3.0916266]\t dist: 0.6293252418516518\n",
      "3. [3.3855442  4.09580511]\t dist: 0.7096675698382892\n",
      "4. [2.83166614 4.26439641]\t dist: 0.7827120549361928\n",
      "5. [3.45334729 2.5996947 ]\t dist: 1.008004667044737\n"
     ]
    }
   ],
   "source": [
    "neighbors = 5\n",
    "# TODO : Use kneighbors to get the most similar instances\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "distances = np.squeeze(distances) # just some trivial processing...\n",
    "data_index = np.squeeze(data_index) # just some trivial processing...\n",
    "\n",
    "print(\"The \" + str(neighbors) + \" nearest neighbors:\")\n",
    "for i in range(neighbors):\n",
    "    print(str(i+1) + \". \" + str(X_train[data_index[i]]) + \"\\t dist: \"+ str(distances[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your output should look like this:__\n",
    "```\n",
    "The 5 nearest neighbors:\n",
    "1. [ 3.53308273  3.67087895]\t dist: 0.559800686629\n",
    "2. [ 2.80923301  2.80047896]\t dist: 0.725066710211\n",
    "3. [ 2.25856168  2.97214525]\t dist: 0.910143626575\n",
    "4. [ 3.99191562  2.99839246]\t dist: 1.11153349516\n",
    "5. [ 3.24464637  2.28448593]\t dist: 1.23988963153\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the labels of the k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[data_index]\n",
    "# We can place in an array as the indices to our array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter k\n",
    "\n",
    "By now, you would have noticed that the value of *k* will affect the result the result of the classifier. Choosing a good *k* is important, and we can do sample runs to see which *k* works best for us.\n",
    "\n",
    "*Hyperparameters* like *k* affect how the model learns, and are usually \"set\" before modelling begins. They are different from regular *parameters* in a model. They are normally considered \"higher level\" because they also help estimate model *paramters*. *Parameters* can be estimated by some analytic solution based on the data, while *hyperparameters* can not. Since knn is non-parametric, we haven't encountered any *parameters* yet.\n",
    "\n",
    "In sklearn's KNeighborsClassifier, we can control the value of *k*, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can change the test data to get a more conflicting labels in the neighbors\n",
    "X_test=[[2,2]] \n",
    "# TODO : Add in the parameter for KNeighborsClassifier so that \n",
    "# it will choose 5 neighbors\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Train the model with the train data\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Test the model with the test data\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How is the label predicted when k is more 1?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the effect when you set the neighbors to 1?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the effect when you set the neighbors to 20?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "So far, we only have one test case. But we can test more than one sample data at a time, we just need to populate more samples in our X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change this\n",
    "X_test = [[0,0],[1,1],[2,2],[3,3],[4,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be an array with n elements, where n is the size of X_test. The predictions will come in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, our validation/test data will have proper labels/ground truths to compare our model's predictions with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[0,0],[1,1],[2,2],[3,3],[4,4]]\n",
    "y_test = [    1,    1,    1,    0,   0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the predictions to y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print out the performance metrics given the actual results vs the predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data set\n",
    "We don't need to manually split our training data from test data. Most of the time, manually splitting your data will be a source of partiality because you may un/consciously be choosing \"good\" or \"easy-to-predict\" data for the model to predict.\n",
    "\n",
    "sklearn also has a module that allows us to easily split our data intro training and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Let's first combine X_train and X_test into a single X\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : Let's first combine y_train and y_test into a single y\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split` to split our train from the test data. Make the test size 33% of the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: \n",
      "[[ 2.83166614  4.26439641]\n",
      " [ 3.16422732  2.15656922]\n",
      " [ 1.57102155  1.1552379 ]\n",
      " [ 1.33512471  1.82438403]\n",
      " [ 1.14581419  4.61391944]\n",
      " [ 2.17264155  0.23400838]\n",
      " [ 3.79654926  4.54100466]\n",
      " [ 0.          0.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 3.          3.        ]\n",
      " [ 3.3855442   4.09580511]\n",
      " [ 2.14877927  0.80819499]\n",
      " [ 1.9801191   1.40172117]\n",
      " [ 2.13413999  1.59058297]\n",
      " [-0.27648426  0.41320186]\n",
      " [-0.79191056  1.08918886]]\n",
      "y train: \n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "X test: \n",
      "[[ 4.39190021  4.01327191]\n",
      " [ 0.20940424 -0.97223719]\n",
      " [ 0.99356347  0.68182588]\n",
      " [ 3.13309955  3.3110279 ]\n",
      " [ 2.5211666   3.0916266 ]\n",
      " [ 3.45334729  2.5996947 ]\n",
      " [-1.35304162  0.66777947]\n",
      " [ 4.          4.        ]\n",
      " [ 2.          2.        ]]\n",
      "y test: \n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We are going to reuse the variables here...\n",
    "# TODO : Call train_test_split\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"X train: \\n\"+ str(X_train))\n",
    "print(\"y train: \\n\"+ str(y_train))\n",
    "print(\"X test: \\n\"+ str(X_test))\n",
    "print(\"y test: \\n\"+ str(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you run the previous cell ang call `train_test_split` again, is it possible to have a different train and test set?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run do modelling like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         5\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO : Create a knn classifier with a k of 3\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think we will come up with a different result if we had a different train and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "Cross validation can be used to decrease the randomness in performance metrics solely because of the test data. \n",
    "\n",
    "__What does cross validation do?__\n",
    "Cross validation is a kind of splitting similar to what we did in the cells before. But it does multiple splits, so cross val will give us *k*   train and test data. It does in such a way that each data point will eventually become a validation data.\n",
    "\n",
    "> The *k* in *k*-fold cross validation is different from *k* nearest neighbors\n",
    "\n",
    "Cross validation is an alternative to split testing where we never shuffle train and test together in further experiments. It is a good option if you have few data points, and you cannot afford to lose any data as test data.\n",
    "\n",
    "__Determining hyperparameters.__ Validation is also a way for us to determine a good value for our *k* in k-nearest neighbors. Instead of blindly choosing our hyperparameter, we will do multiple experiments using cross validation to see which one will give us the best results.\n",
    "\n",
    "> You may have heard of *validation* and *test* data before. For now, we will treat them similarly. But they are two different things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_predict` does the data splitting, training, and cross-validation. Try getting the predictions using a *k* of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.92      0.92        12\n",
      "         1.0       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92        25\n",
      "   macro avg       0.92      0.92      0.92        25\n",
      "weighted avg       0.92      0.92      0.92        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "k = 10\n",
    "# TODO : get the predictions using cross_val_predict\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# TODO : print the classification report\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The result should look something like this :__\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.73      0.92      0.81        12\n",
    "        1.0       0.90      0.69      0.78        13\n",
    "\n",
    "avg / total       0.82      0.80      0.80        25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also use `cross_val_score` to get the actual accuracy from each fold in the k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores per fold :\n",
      "[1.    0.875 1.   ]\n",
      "Average accuracy : 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# See the scores per fold (experiment)\n",
    "k=3\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "scores = cross_val_score(model, X, y, cv=3)\n",
    "print(\"Scores per fold :\\n\" + str(scores))\n",
    "print(\"Average accuracy : \" + str(np.sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The result should look something like this :__\n",
    "```\n",
    "Scores per fold :\n",
    "[ 1.    0.75  0.    1.    0.5   1.    1.    1.    1.    1.  ]\n",
    "Average accuracy : 0.825\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
